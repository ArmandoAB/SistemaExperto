{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizador Lexico\n",
    "Un analizador lexico transforma una entrada en tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class TipoToken(Enum):  #sistema para clasificación de palabras y conectores\n",
    "    O = 1\n",
    "    Y = 2\n",
    "    S = 3\n",
    "    N = 4\n",
    "    E = 5\n",
    "    P = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "lexemas = []\n",
    "\n",
    "def Analizador_lexico(entrada : str) -> list:\n",
    "    lexemas.clear()\n",
    "    tokens = entrada.lower().split()\n",
    "    for token in tokens:\n",
    "        if token == 'o':\n",
    "            lexemas.append({\"valor\": token , \"tipo\": TipoToken.O })\n",
    "        elif token == 'y':\n",
    "            lexemas.append({\"valor\": token , \"tipo\": TipoToken.Y})\n",
    "        elif token == 'si':\n",
    "            lexemas.append({\"valor\": token , \"tipo\": TipoToken.S})\n",
    "        elif token == 'entonces':\n",
    "            lexemas.append({\"valor\": token , \"tipo\": TipoToken.E})\n",
    "        elif token == 'no':\n",
    "            lexemas.append({\"valor\": token , \"tipo\": TipoToken.N})\n",
    "        else :\n",
    "            lexemas.append({\"valor\":token , \"tipo\": TipoToken.P })\n",
    "            \n",
    "    return(lexemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizador Sintactico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstadosAnalizador(Enum):  #Sistema de guardado de Estados\n",
    "    INICIO = 1\n",
    "    PRECEDENTE = 2\n",
    "    NEGACION = 3\n",
    "    CONSECUENTE = 4\n",
    "    DISYUNCION = 5\n",
    "    CONJUNCION = 6\n",
    "    ATOMO = 7\n",
    "    ERROR1 = 8  #se esperaba un 'si', 'no' o un atomo\n",
    "    ERROR2 = 9  #se esperaba un 'no' o un atomo\n",
    "    ERROR3 = 10 #se esperaba un 'y', 'o', 'entonces' o un atomo\n",
    "    ERROR4 = 11 #se esperaba un atomo\n",
    "    ERROR5 = 12 #no se encontro un 'si' antes de 'entonces'\n",
    "    FIN = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_reglas = []\n",
    "atomos = []\n",
    "\n",
    "def Analizador_sintactico(lexemas : list):\n",
    "    regla = \"\"\n",
    "    pila = \"\"\n",
    "    prec = 0\n",
    "    pila = []\n",
    "    prop = \"\"\n",
    "\n",
    "    EstadoActual = EstadosAnalizador.INICIO\n",
    "\n",
    "#INICIO\n",
    "    for lexema in lexemas:\n",
    "        if EstadoActual == EstadosAnalizador.INICIO:\n",
    "            if lexema['valor'] == \"si\":\n",
    "                EstadoActual = EstadosAnalizador.PRECEDENTE\n",
    "                prec = 1\n",
    "            elif lexema['valor'] == \"no\":\n",
    "                EstadoActual = EstadosAnalizador.NEGACION\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += \"~\"\n",
    "            elif lexema['tipo'] == TipoToken.P:\n",
    "                EstadoActual = EstadosAnalizador.ATOMO\n",
    "                pila.append(lexema['valor'])\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ERROR1\n",
    "\n",
    "#Precedente\n",
    "        elif EstadoActual == EstadosAnalizador.PRECEDENTE:\n",
    "            if lexema['valor'] == \"no\":\n",
    "                EstadoActual = EstadosAnalizador.NEGACION\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += \"~\"\n",
    "            elif lexema['tipo'] == TipoToken.P:\n",
    "                EstadoActual = EstadosAnalizador.ATOMO\n",
    "                pila.append(lexema['valor'])\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ERROR2\n",
    "\n",
    "#Negacion\n",
    "        elif EstadoActual == EstadosAnalizador.NEGACION:\n",
    "            if lexema['tipo'] == TipoToken.P:\n",
    "                EstadoActual = EstadosAnalizador.ATOMO\n",
    "                pila.append(lexema['valor'])\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ERROR3\n",
    "\n",
    "#Consecuente\n",
    "        elif EstadoActual == EstadosAnalizador.CONSECUENTE:\n",
    "            if lexema['tipo'] == TipoToken.P:\n",
    "                EstadoActual = EstadosAnalizador.ATOMO\n",
    "                pila.append(lexema['valor'])\n",
    "            elif lexema['valor'] == \"no\":\n",
    "                EstadoActual = EstadosAnalizador.NEGACION\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += \"~\"\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ERROR2\n",
    "\n",
    "#Atomo\n",
    "        elif EstadoActual == EstadosAnalizador.ATOMO:\n",
    "            if lexema['valor'] == \"entonces\" and prec == 1:\n",
    "                EstadoActual = EstadosAnalizador.CONSECUENTE\n",
    "                prop = \" \".join(pila)\n",
    "                atomos.append(prop)\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += prop\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += \"->\"\n",
    "                pila.clear()\n",
    "                prop = \"\"\n",
    "            elif lexema['valor'] == \"y\":\n",
    "                EstadoActual = EstadosAnalizador.CONJUNCION\n",
    "                prop = \" \".join(pila)\n",
    "                atomos.append(prop)\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += prop\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += \"&\"\n",
    "                pila.clear()\n",
    "                prop = \"\"\n",
    "            elif lexema['valor'] == \"o\":\n",
    "                EstadoActual = EstadosAnalizador.DISYUNCION\n",
    "                prop = \" \".join(pila)\n",
    "                atomos.append(prop)\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += prop\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += \"V\"\n",
    "                pila.clear()\n",
    "                prop = \"\"\n",
    "            elif lexema['tipo'] == TipoToken.P:\n",
    "                EstadoActual = EstadosAnalizador.ATOMO\n",
    "                pila.append(lexema['valor'])\n",
    "            elif lexema['valor'] == \"entonces\" and prec == 0:\n",
    "                EstadoActual = EstadosAnalizador.ERROR5\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ERROR3\n",
    "\n",
    "#Conjuncion\n",
    "        elif EstadoActual == EstadosAnalizador.CONJUNCION:\n",
    "            if lexema['tipo'] == TipoToken.P:\n",
    "                EstadoActual = EstadosAnalizador.ATOMO\n",
    "                pila.append(lexema['valor'])\n",
    "            elif lexema['valor'] == \"no\":\n",
    "                EstadoActual = EstadosAnalizador.NEGACION\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += \"~\"\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ERROR2\n",
    "                \n",
    "#Disyuncion\n",
    "        elif EstadoActual == EstadosAnalizador.DISYUNCION:\n",
    "            if lexema['tipo'] == TipoToken.P:\n",
    "                EstadoActual = EstadosAnalizador.ATOMO\n",
    "                pila.append(lexema['valor'])\n",
    "            elif lexema['valor'] == \"no\":\n",
    "                EstadoActual == EstadosAnalizador.NEGACION\n",
    "                if regla:\n",
    "                    regla += \" \"\n",
    "                regla += \"~\"\n",
    "            else:\n",
    "                EstadoActual = EstadosAnalizador.ERROR2\n",
    "\n",
    "#Errores\n",
    "        elif EstadoActual == EstadosAnalizador.ERROR1:\n",
    "            print(\"se esperaba un 'si', 'no' o un atomo\")\n",
    "            regla = \"\"\n",
    "            prop = \"\"\n",
    "            pila.clear()\n",
    "            break\n",
    "        elif EstadoActual == EstadosAnalizador.ERROR2:\n",
    "            print(\"se esperaba un 'no' o un atomo\")\n",
    "            regla = \"\"\n",
    "            prop = \"\"\n",
    "            pila.clear()\n",
    "            break\n",
    "        elif EstadoActual == EstadosAnalizador.ERROR3:\n",
    "            regla = \"\"\n",
    "            prop = \"\"\n",
    "            pila.clear()\n",
    "            print(\"se esperaba un 'y', 'o', 'entonces' o un atomo\")\n",
    "            break\n",
    "        elif EstadoActual == EstadosAnalizador.ERROR4:\n",
    "            print(\"se esperaba un atomo\")\n",
    "            regla = \"\"\n",
    "            prop = \"\"\n",
    "            pila.clear()\n",
    "            break\n",
    "        elif EstadoActual == EstadosAnalizador.ERROR5:\n",
    "            print(\"no se encontro un 'si' antes de 'entonces'\")\n",
    "            regla = \"\"\n",
    "            prop = \"\"\n",
    "            pila.clear()\n",
    "            break\n",
    "        else:\n",
    "            EstadoActual == EstadosAnalizador.FIN\n",
    "\n",
    "#Salida sin errores\n",
    "    if EstadoActual != (EstadosAnalizador.ERROR1 and EstadosAnalizador.ERROR2 and EstadosAnalizador.ERROR3 and EstadosAnalizador.ERROR4 and EstadosAnalizador.ERROR5):\n",
    "        prop = \" \".join(pila)\n",
    "        atomos.append(prop)\n",
    "        if regla and prop:\n",
    "            regla += \" \" + prop\n",
    "        else:\n",
    "            regla = prop\n",
    "        l_reglas.append(regla)\n",
    "        prop = \"\"\n",
    "        pila.clear()\n",
    "        regla = \"\"\n",
    "        print(\"proposicion valida\")\n",
    "    \n",
    "    return(l_reglas, atomos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proposicion valida\n",
      "proposicion valida\n",
      "['es de dia V es de noche -> existo', 'es de dia']\n",
      "['es de dia', 'es de noche', 'existo', 'es de dia']\n"
     ]
    }
   ],
   "source": [
    "Palabras = []\n",
    "l_reglas.clear()\n",
    "lexemas.clear()\n",
    "atomos.clear()\n",
    "\n",
    "frases = [\n",
    "    \"Si es de dia o es de noche entonces existo\",\n",
    "    \"Es de dia\"]\n",
    "\n",
    "for frase in frases:\n",
    "    Palabras.clear()\n",
    "    Palabras = Analizador_lexico(frase)\n",
    "    Analizador_sintactico(Palabras)\n",
    "\n",
    "print(l_reglas)\n",
    "print(atomos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de lectura de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proposicion valida\n",
      "proposicion valida\n",
      "proposicion valida\n",
      "proposicion valida\n",
      "proposicion valida\n",
      "proposicion valida\n",
      "proposicion valida\n",
      "proposicion valida\n",
      "proposicion valida\n",
      "proposicion valida\n"
     ]
    }
   ],
   "source": [
    "Palabras = []\n",
    "l_reglas.clear()\n",
    "lexemas.clear()\n",
    "atomos.clear()\n",
    "\n",
    "with open(\"reglas-texto.txt\", \"r\") as archivo:\n",
    "    lineas = archivo.readlines()\n",
    "\n",
    "erease = \"\\n\"\n",
    "enun = []\n",
    "for linea in lineas:\n",
    "    ent = linea.replace(erease, \"\")\n",
    "    enun.append(ent)\n",
    "\n",
    "for frase in enun:\n",
    "    Palabras.clear()\n",
    "    Palabras = Analizador_lexico(frase)\n",
    "    Analizador_sintactico(Palabras)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimina atomos repetidos en la lista de atomos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = set()\n",
    "atomos_unicos = []\n",
    "\n",
    "for atomo in atomos:\n",
    "    if atomo not in seen:\n",
    "        atomos_unicos.append(atomo)\n",
    "        seen.add(atomo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reemplaza los atomos con sus numeros en la regla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['~ P0 -> ~ P1 V ~ P2 V ~ P3',\n",
       " 'P4 V P5 -> P6 V P7',\n",
       " '~ P2 -> P1 V P3',\n",
       " 'P8 -> P1 V P9',\n",
       " 'P10 & ~ P0 -> P11',\n",
       " 'P12 -> P13 V P6',\n",
       " 'P14 & ~ P11 V ~ P9 -> P15 V P16',\n",
       " 'P17 -> P16 V P1 V P18',\n",
       " 'P19 -> P13 V P11 V P9',\n",
       " 'P20 -> P6 V P3']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reglasx = []\n",
    "NoPrep : str\n",
    "\n",
    "for regla in l_reglas:\n",
    "    temp = regla\n",
    "    for index, atomo in enumerate(atomos_unicos):\n",
    "        NoPrep = \"P\" + str(index)\n",
    "        if atomo in regla:\n",
    "            temp = temp.replace(atomo, NoPrep)\n",
    "    reglasx.append(temp)\n",
    "\n",
    "reglasx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafos de las reglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from graphviz import Digraph\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "def parse_expression(expression):\n",
    "    # Actualizar la expresión regular para los nuevos operadores y para combinar ~ con el operando\n",
    "    expression = re.sub(r'~\\s+', '~', expression)\n",
    "    tokens = re.findall(r'~?\\w+|->|&|V', expression)\n",
    "    return tokens\n",
    "\n",
    "def build_tree(tokens):\n",
    "    # Manejar el consecuente como raíz\n",
    "    if '->' in tokens:\n",
    "        index = tokens.index('->')\n",
    "        left_expr = tokens[:index]\n",
    "        right_expr = tokens[index + 1:]\n",
    "        root = Node('->')\n",
    "        root.left = build_tree(left_expr)\n",
    "        root.right = build_tree(right_expr)\n",
    "        return root\n",
    "\n",
    "    # Función para manejar operadores binarios\n",
    "    def parse_tokens(tokens):\n",
    "        # Prioridad: V -> &\n",
    "        # Primero manejar &\n",
    "        while '&' in tokens:\n",
    "            index = tokens.index('&')\n",
    "            left = tokens[:index]\n",
    "            right = tokens[index + 1:]\n",
    "            node = Node('&')\n",
    "            node.left = parse_tokens(left)\n",
    "            node.right = parse_tokens(right)\n",
    "            return node\n",
    "\n",
    "        # Luego manejar V\n",
    "        while 'V' in tokens:\n",
    "            index = tokens.index('V')\n",
    "            left = tokens[:index]\n",
    "            right = tokens[index + 1:]\n",
    "            node = Node('V')\n",
    "            node.left = parse_tokens(left)\n",
    "            node.right = parse_tokens(right)\n",
    "            return node\n",
    "        \n",
    "        # Manejar la negación como un operador unario\n",
    "        if tokens[0].startswith('~'):\n",
    "            node = Node(tokens[0])\n",
    "            return node\n",
    "        else:   # Operando simple\n",
    "            return Node(tokens[0])\n",
    "\n",
    "    return parse_tokens(tokens)\n",
    "\n",
    "def visualize_tree(node):\n",
    "    dot = Digraph()\n",
    "    def add_nodes_edges(node):\n",
    "        if node is not None:\n",
    "            dot.node(str(id(node)), node.value)\n",
    "            if node.left:\n",
    "                dot.edge(str(id(node)), str(id(node.left)))\n",
    "                add_nodes_edges(node.left)\n",
    "            if node.right:\n",
    "                dot.edge(str(id(node)), str(id(node.right)))\n",
    "                add_nodes_edges(node.right)\n",
    "    add_nodes_edges(node)\n",
    "    return dot\n",
    "\n",
    "def process_expressions(expressions):\n",
    "    for i, expression in enumerate(expressions):\n",
    "        tokens = parse_expression(expression)\n",
    "        tree = build_tree(tokens)\n",
    "        dot = visualize_tree(tree)\n",
    "        dot.render(f'logic_tree_{i}', format='png', view=False)\n",
    "\n",
    "process_expressions(reglasx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbol binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arbol:\n",
    "    # Funciones privadas\n",
    "    def __init__(self, dato):\n",
    "        self.raiz = Nodo(dato)\n",
    "\n",
    "    def __agregar_recursivo(self, nodo, dato):\n",
    "        if dato < nodo.dato:\n",
    "            if nodo.izquierda is None:\n",
    "                nodo.izquierda = Nodo(dato)\n",
    "            else:\n",
    "                self.__agregar_recursivo(nodo.izquierda, dato)\n",
    "        else:\n",
    "            if nodo.derecha is None:\n",
    "                nodo.derecha = Nodo(dato)\n",
    "            else:\n",
    "                self.__agregar_recursivo(nodo.derecha, dato)\n",
    "\n",
    "    def __inorden_recursivo(self, nodo):\n",
    "        if nodo is not None:\n",
    "            self.__inorden_recursivo(nodo.izquierda)\n",
    "            print(nodo.dato, end=\", \")\n",
    "            self.__inorden_recursivo(nodo.derecha)\n",
    "\n",
    "    def __preorden_recursivo(self, nodo):\n",
    "        if nodo is not None:\n",
    "            print(nodo.dato, end=\", \")\n",
    "            self.__preorden_recursivo(nodo.izquierda)\n",
    "            self.__preorden_recursivo(nodo.derecha)\n",
    "\n",
    "    def __postorden_recursivo(self, nodo):\n",
    "        if nodo is not None:\n",
    "            self.__postorden_recursivo(nodo.izquierda)\n",
    "            self.__postorden_recursivo(nodo.derecha)\n",
    "            print(nodo.dato, end=\", \")\n",
    "\n",
    "    def __buscar(self, nodo, busqueda):\n",
    "        if nodo is None:\n",
    "            return None\n",
    "        if nodo.dato == busqueda:\n",
    "            return nodo\n",
    "        if busqueda < nodo.dato:\n",
    "            return self.__buscar(nodo.izquierda, busqueda)\n",
    "        else:\n",
    "            return self.__buscar(nodo.derecha, busqueda)\n",
    "\n",
    "    # Funciones públicas\n",
    "\n",
    "    def agregar(self, dato):\n",
    "        self.__agregar_recursivo(self.raiz, dato)\n",
    "\n",
    "    def inorden(self):\n",
    "        print(\"Imprimiendo árbol inorden: \")\n",
    "        self.__inorden_recursivo(self.raiz)\n",
    "        print(\"\")\n",
    "\n",
    "    def preorden(self):\n",
    "        print(\"Imprimiendo árbol preorden: \")\n",
    "        self.__preorden_recursivo(self.raiz)\n",
    "        print(\"\")\n",
    "\n",
    "    def postorden(self):\n",
    "        print(\"Imprimiendo árbol postorden: \")\n",
    "        self.__postorden_recursivo(self.raiz)\n",
    "        print(\"\")\n",
    "\n",
    "    def buscar(self, busqueda):\n",
    "        return self.__buscar(self.raiz, busqueda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"239pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 238.66 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 234.66,-184 234.66,4 -4,4\"/>\n",
       "<!-- 1943915759168 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1943915759168</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"87.58\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.58\" y=\"-156.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;&gt;</text>\n",
       "</g>\n",
       "<!-- 1943916004928 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1943916004928</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"43.58\" cy=\"-90\" rx=\"43.58\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43.58\" y=\"-84.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">es de dia</text>\n",
       "</g>\n",
       "<!-- 1943915759168&#45;&gt;1943916004928 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1943915759168&#45;&gt;1943916004928</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M77.59,-145.12C72.46,-136.94 66.05,-126.76 60.2,-117.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.23,-115.68 54.94,-109.08 57.3,-119.41 63.23,-115.68\"/>\n",
       "</g>\n",
       "<!-- 1943916004880 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1943916004880</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"132.58\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"132.58\" y=\"-84.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\n",
       "</g>\n",
       "<!-- 1943915759168&#45;&gt;1943916004880 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1943915759168&#45;&gt;1943916004880</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.79,-145.12C103.26,-136.61 110.12,-125.94 116.3,-116.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.13,-118.4 121.59,-108.09 113.24,-114.61 119.13,-118.4\"/>\n",
       "</g>\n",
       "<!-- 1943916005072 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>1943916005072</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"77.58\" cy=\"-18\" rx=\"48.57\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"77.58\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">hace calor</text>\n",
       "</g>\n",
       "<!-- 1943916004880&#45;&gt;1943916005072 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1943916004880&#45;&gt;1943916005072</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M120.37,-73.46C113.66,-64.92 105.16,-54.1 97.51,-44.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.38,-42.36 91.45,-36.66 94.88,-46.68 100.38,-42.36\"/>\n",
       "</g>\n",
       "<!-- 1943916005168 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1943916005168</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"187.58\" cy=\"-18\" rx=\"43.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.58\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">hace frio</text>\n",
       "</g>\n",
       "<!-- 1943916004880&#45;&gt;1943916005168 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1943916004880&#45;&gt;1943916005168</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.79,-73.46C151.5,-64.92 160,-54.1 167.65,-44.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.28,-46.68 173.71,-36.66 164.77,-42.36 170.28,-46.68\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1c49a68b9a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "def generate_tree():\n",
    "    # Crear el árbol de expresiones\n",
    "    root = Node('->')\n",
    "    node1 = Node('es de dia')\n",
    "    node2 = Node('v')\n",
    "    node3 = Node('hace calor')\n",
    "    node4 = Node('hace frio')\n",
    "\n",
    "    root.add_child(node1)\n",
    "    root.add_child(node2)\n",
    "    node2.add_child(node3)\n",
    "    node2.add_child(node4)\n",
    "\n",
    "    return root\n",
    "def visualize_tree(root):\n",
    "    dot = graphviz.Digraph()\n",
    "\n",
    "    def traverse(node):\n",
    "        dot.node(str(id(node)), node.value)\n",
    "        for child in node.children:\n",
    "            dot.edge(str(id(node)), str(id(child)))\n",
    "            traverse(child)\n",
    "\n",
    "    traverse(root)\n",
    "    display(dot)\n",
    "root = generate_tree()\n",
    "visualize_tree(root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
